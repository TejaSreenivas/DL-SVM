{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from load_cifar import load_data\n",
    "import new_model as model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset (cifar-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data('C:/Users/k_tej/Documents/TEJA/ML_resources/DL_projects/data_sets/cifar-10-batches-py')\n",
    "#data = load_data('/floyd/input/cifar_10_batches_py/cifar-10-batches-py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train_x', 'train_y', 'test_x', 'test_y'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((50000, 32, 32, 3), (50000,)), ((10000, 32, 32, 3), (10000,)))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data['train_x'].shape,data['train_y'].shape),(data['test_x'].shape,data['test_y'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = 32\n",
    "CH = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: horse\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26f08be9cf8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.random.randint(50000)\n",
    "print('Label: {}'.format(labels[data['train_y'][x]]))\n",
    "plt.imshow(data['train_x'][x].reshape(DIM,DIM,CH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.  One hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 10), (10000, 10))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = 10\n",
    "id_mtx = np.identity(n_classes,dtype=np.float32)\n",
    "data['train_y'] = id_mtx[data['train_y']]\n",
    "data['test_y'] = id_mtx[data['test_y']]\n",
    "data['train_y'].shape, data['test_y'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Normalize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['train_x'] = data['train_x'].astype(np.float32)/255\n",
    "data['test_x'] = data['test_x'].astype(np.float32)/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain_x = tf.data.Dataset.from_tensor_slices(data['train_x'])\n",
    "dtrain_y = tf.data.Dataset.from_tensor_slices(data['train_y'])\n",
    "dtrain = tf.data.Dataset.zip(( dtrain_x, dtrain_y )).repeat().batch(batch_size)\n",
    "dtrain_one_shot = tf.data.Dataset.zip(( dtrain_x, dtrain_y )).batch(batch_size)\n",
    "\n",
    "dtest_x = tf.data.Dataset.from_tensor_slices(data['test_x'])\n",
    "dtest_y = tf.data.Dataset.from_tensor_slices(data['test_y'])\n",
    "dtest = tf.data.Dataset.zip(( dtest_x,dtest_y )).batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<BatchDataset shapes: ((?, 32, 32, 3), (?, 10)), types: (tf.float32, tf.float32)>,\n",
       " <BatchDataset shapes: ((?, 32, 32, 3), (?, 10)), types: (tf.float32, tf.float32)>,\n",
       " <BatchDataset shapes: ((?, 32, 32, 3), (?, 10)), types: (tf.float32, tf.float32)>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dvalid_x = tf.data.Dataset.from_tensor_slices(data['test_x'][:1000,:,:,:])\n",
    "dvalid_y = tf.data.Dataset.from_tensor_slices(data['test_y'][:1000])\n",
    "dvalid = tf.data.Dataset.zip(( dtest_x,dtest_y )).repeat().batch(batch_size)\n",
    "(dtrain,dtest,dvalid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = tf.data.Iterator.from_structure(dtrain.output_types,dtrain.output_shapes)\n",
    "get_batch = iterator.get_next()\n",
    "\n",
    "#for train\n",
    "dtrain_init = iterator.make_initializer(dtrain)\n",
    "#for test\n",
    "dtest_init = iterator.make_initializer(dtest)\n",
    "#for validation\n",
    "dvalid_init = iterator.make_initializer(dvalid)\n",
    "#for one shot\n",
    "one_shot_init = iterator.make_initializer(dtrain_one_shot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "epochs = int(epochs*50000/(batch_size))\n",
    "probability_keep = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 32 and 64 for 'conv_3/Conv2D' (op: 'Conv2D') with input shapes: [?,16,16,32], [3,3,64,128].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1588\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1589\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1590\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 32 and 64 for 'conv_3/Conv2D' (op: 'Conv2D') with input shapes: [?,16,16,32], [3,3,64,128].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-472e657058de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mis_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprob_keep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcurrent_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob_keep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mparam_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\TEJA\\ML_resources\\DL_projects\\SVM-DL\\DL-SVM\\new_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, is_train, prob_keep)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob_keep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob_keep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\TEJA\\ML_resources\\DL_projects\\SVM-DL\\DL-SVM\\new_model.py\u001b[0m in \u001b[0;36mcnn\u001b[1;34m(self, data, is_train, prob_keep)\u001b[0m\n\u001b[0;32m     46\u001b[0m                 \u001b[0ml3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"conv_3\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAUTO_REUSE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m                         \u001b[0mconv3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_conv_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"SAME\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m                         \u001b[0mconv3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_normalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m                         \u001b[0mconv3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\TEJA\\ML_resources\\DL_projects\\SVM-DL\\DL-SVM\\new_model.py\u001b[0m in \u001b[0;36mcreate_conv_layer\u001b[1;34m(self, inp, filters, stride, padding)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcreate_conv_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[0mwt\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weight'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtruncated_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstddev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[0mconv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m                 \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bias'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitializer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1040\u001b[0m         \u001b[1;34m\"Conv2D\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m         data_format=data_format, dilations=dilations, name=name)\n\u001b[0m\u001b[0;32m   1043\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   3412\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3413\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3414\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3416\u001b[0m       \u001b[1;31m# Note: shapes are lazily computed with the C API enabled.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1754\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1755\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1756\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1757\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1758\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1590\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1591\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1592\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1594\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions must be equal, but are 32 and 64 for 'conv_3/Conv2D' (op: 'Conv2D') with input shapes: [?,16,16,32], [3,3,64,128]."
     ]
    }
   ],
   "source": [
    "is_train = tf.placeholder(shape=(),dtype=tf.bool)\n",
    "prob_keep = tf.placeholder(shape=(),dtype=tf.float32)\n",
    "current_model = model.CNN(get_batch[0], is_train, prob_keep)\n",
    "param_info = current_model.total_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits=current_model.logits\n",
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.softmax_cross_entropy(labels=get_batch[1],logits=logits)\n",
    "tf.summary.scalar(\"losses\",loss)\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "predictions = tf.argmax(logits,axis=1)\n",
    "equality = tf.equal(predictions,tf.argmax(get_batch[1],axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(equality,tf.float32))\n",
    "tf.summary.scalar(\"accuracy\",accuracy)\n",
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = 'floyd/home/logs'\n",
    "print(log_dir)\n",
    "t_summary = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stack = np.random.rand(1,n_classes)\n",
    "test_stack = np.random.rand(1,n_classes)\n",
    "valid_log_acc = []\n",
    "train_log_acc=[]\n",
    "test_acc=[]\n",
    "train_acc=[]\n",
    "with tf.Session() as sess:\n",
    "    writer.add_graph(sess.graph)\n",
    "    sess.run(init_op)\n",
    "    train_log_loss = []\n",
    "    valid_log_loss = []\n",
    "    for i in range(1,epochs+1):\n",
    "        sess.run(dtrain_init)\n",
    "        l,_,acc,s = sess.run([loss,optimizer,accuracy,t_summary],feed_dict={is_train:True,prob_keep:probability_keep})\n",
    "        writer.add_summary(s,i)\n",
    "        train_log_loss.append(l)\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            print(\"epoch :{}, loss :{:.3f}, accuracy :{:.3f}\".format(i,l,acc))\n",
    "            #save_path = saver.save(sess,log_dir+'/curr_model.ckpt')\n",
    "            valid_iter = 10\n",
    "            avg_acc = 0\n",
    "            sess.run(dvalid_init)\n",
    "            for _ in range(valid_iter):\n",
    "                acc = sess.run([accuracy],feed_dict = {is_train:False,prob_keep:1.0})\n",
    "                avg_acc+=acc[0]\n",
    "            avg_acc = avg_acc*100.0/10\n",
    "            valid_log_acc.append(avg_acc)\n",
    "            print(\"average accuracy :{:.2f}\".format(avg_acc))\n",
    "    \n",
    "    i = 0\n",
    "    test_acc = 0\n",
    "    sess.run(dtest_init)\n",
    "    while True:\n",
    "        try:\n",
    "            acc,test_out = sess.run([accuracy,logits],feed_dict={is_train:False,prob_keep:1.0})\n",
    "            test_stack = np.vstack((test_stack,test_out))\n",
    "            i+=1\n",
    "            test_acc+=acc\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"number of iter : {}\".format(i))\n",
    "            test_acc = test_acc*100/i\n",
    "            print(\"Test accuracy: {}\".format(test_acc))\n",
    "            plt.plot(train_log_loss,label='loss_train',color='r')\n",
    "            plt.plot(np.array(list(range(1,int(epochs/100)+1)))*100,valid_log_acc,label='acc_train',color='b')\n",
    "            plt.xlabel('epochs')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            break\n",
    "    train_acc = 0\n",
    "    i=0\n",
    "    sess.run(one_shot_init)\n",
    "    while True:\n",
    "        try:\n",
    "            acc,train_out =sess.run([accuracy,logits],feed_dict={is_train:False,prob_keep:1.0})\n",
    "            i+=1\n",
    "            train_stack = np.vstack((train_stack,train_out))\n",
    "            train_acc+=acc\n",
    "        except:\n",
    "            train_acc = train_acc*100/i\n",
    "            print(\"train accuracy: {:.3f}\".format(train_acc))\n",
    "            break\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = dict()\n",
    "output_dict['batch_size'] = batch_size\n",
    "output_dict['epochs'] = epochs\n",
    "output_dict['loss'] = np.array(train_log_loss)\n",
    "output_dict['accuracy'] = np.array(valid_log_acc)\n",
    "output_dict['test_accuracy'] = np.array(test_acc)\n",
    "output_dict['train_accuracy'] = np.array(train_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.save('data_info_epochs_1.npy',output_dict)\n",
    "np.savetxt('train_stack.csv',train_stack[1:],delimiter=',')\n",
    "np.savetxt('test_stack.csv',test_stack[1:],delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.save('/floyd/home/data_info_epoch_1.npy',output_dict)\n",
    "np.savetxt('/floyd/home/train_stack.csv',train_stack[1:],delimiter=',')\n",
    "np.savetxt('/floyd/home/test_stack.csv',test_stack[1:],delimiter=',')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
